{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XquB6Iw6GxRu",
        "outputId": "67882321-19b8-411b-ac3a-f9899edfc929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import all the necessary libraries into the project."
      ],
      "metadata": {
        "id": "5c5EIFLOr1Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "!pip install pymorphy2 nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import pymorphy2"
      ],
      "metadata": {
        "id": "1Di0NY8gLkhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7618f7-a61a-48c4-cbf8-891c8251bb57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's list all of the artists that will be used in the project."
      ],
      "metadata": {
        "id": "J3f4lkpSsBNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jazz_artists = [\"Billie Holiday\", \"Chet Baker\", \"Ella Fitzgerald\", \"Louis Armstrong\"]\n",
        "pop_artists = [\"Billie Eilish\", \"Bruno Mars\", \"BTS\", \"Dua Lipa\", \"Ed Sheeran\", \"Harry Styles\", \"ITZY\", \"Lady Gaga\", \"Lizzo\", \"Taylor Swift\"]\n",
        "rap_artists = [\"Drake\", \"Eminem\", \"Kanye West\", \"Kendrick Lamar\", \"Post Malone\", \"Tyler, The Creator\"]\n",
        "rock_artists = [\"AC-DC\", \"Def Leppard\", \"Fleetwood Mac\", \"Glass Animals\", \"Imagine Dragons\", \"Journey\", \"Lynyrd Skynyrd\", \"Queen\"]\n",
        "artists = {'jazz': jazz_artists, 'pop': pop_artists, 'rap': rap_artists, 'rock': rock_artists}"
      ],
      "metadata": {
        "id": "8xKAOg_mamOI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a database by looping over all of the files and appending it to one big array, which will then be used to transform into a DataFrame with the pandas library"
      ],
      "metadata": {
        "id": "AgBzmCv9sIUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "for genre in artists.keys():\n",
        "  genre_path = os.path.join(\"/content/gdrive/MyDrive/FP/\", genre)\n",
        "  for artist in artists[genre]:\n",
        "    lyrics_path = os.path.join(genre_path, artist)\n",
        "    lyrics_files = os.listdir(lyrics_path)\n",
        "    for lyrics in lyrics_files:\n",
        "      f = open(os.path.join(lyrics_path, lyrics))\n",
        "      lines = f.read()\n",
        "      if artist is not 'ITZY' and artist is not 'BTS':\n",
        "        data.append({'Artist': artist, 'Title': lyrics[:-4], 'Genre': genre, 'Language': 'en', 'Lyrics': lines})\n",
        "      else:\n",
        "        data.append({'Artist': artist, 'Title': lyrics[:-4], 'Genre': genre, 'Language': 'kn', 'Lyrics': lines})\n",
        "      f.close()\n",
        "        "
      ],
      "metadata": {
        "id": "oFdgeAZRkCb8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs = pd.DataFrame(data)\n",
        "songs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Lw2kuaRPtBmX",
        "outputId": "7bedd018-c1c0-4d78-92d5-4465aee92cfc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Artist                                Title Genre Language  \\\n",
              "0     Billie Holiday     ’Tain’t Nobody’s Bizness If I Do  jazz       en   \n",
              "1     Billie Holiday  (I Don’t Stand A) Ghost of a Chance  jazz       en   \n",
              "2     Billie Holiday             (This Is) My Last Affair  jazz       en   \n",
              "3     Billie Holiday                       24 Hours A Day  jazz       en   \n",
              "4     Billie Holiday                       A Fine Romance  jazz       en   \n",
              "...              ...                                  ...   ...      ...   \n",
              "5104           Queen                         Wishing Well  rock       en   \n",
              "5105           Queen                            You and I  rock       en   \n",
              "5106           Queen                    You Don’t Fool Me  rock       en   \n",
              "5107           Queen              You Take My Breath Away  rock       en   \n",
              "5108           Queen                You’re My Best Friend  rock       en   \n",
              "\n",
              "                                                 Lyrics  \n",
              "0     There ain't nothing I can do\\nOr nothing I can...  \n",
              "1     I need your love so badly\\nI love you, oh, so ...  \n",
              "2     Can't you see\\nWhat love and romance have done...  \n",
              "3     Like a little old fashioned music box\\nWith ju...  \n",
              "4     A fine romance with no kisses\\nA fine romance,...  \n",
              "...                                                 ...  \n",
              "5104  Throw down your hat, kick off your shoes\\nI kn...  \n",
              "5105  Ooh-ooh\\n\\nMusic is playing in the darkness\\nA...  \n",
              "5106  Oh\\n\\nYou don't fool me, you don't fool me\\nYo...  \n",
              "5107  Ooh\\nOoh, take it, take it all away\\nOoh\\nOoh,...  \n",
              "5108  Ooh, you make me live\\nWhatever this world can...  \n",
              "\n",
              "[5109 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc592835-615f-41d7-a1ac-7c4fb5c99988\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Artist</th>\n",
              "      <th>Title</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Language</th>\n",
              "      <th>Lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Billie Holiday</td>\n",
              "      <td>’Tain’t Nobody’s Bizness If I Do</td>\n",
              "      <td>jazz</td>\n",
              "      <td>en</td>\n",
              "      <td>There ain't nothing I can do\\nOr nothing I can...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Billie Holiday</td>\n",
              "      <td>(I Don’t Stand A) Ghost of a Chance</td>\n",
              "      <td>jazz</td>\n",
              "      <td>en</td>\n",
              "      <td>I need your love so badly\\nI love you, oh, so ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Billie Holiday</td>\n",
              "      <td>(This Is) My Last Affair</td>\n",
              "      <td>jazz</td>\n",
              "      <td>en</td>\n",
              "      <td>Can't you see\\nWhat love and romance have done...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Billie Holiday</td>\n",
              "      <td>24 Hours A Day</td>\n",
              "      <td>jazz</td>\n",
              "      <td>en</td>\n",
              "      <td>Like a little old fashioned music box\\nWith ju...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Billie Holiday</td>\n",
              "      <td>A Fine Romance</td>\n",
              "      <td>jazz</td>\n",
              "      <td>en</td>\n",
              "      <td>A fine romance with no kisses\\nA fine romance,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5104</th>\n",
              "      <td>Queen</td>\n",
              "      <td>Wishing Well</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Throw down your hat, kick off your shoes\\nI kn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5105</th>\n",
              "      <td>Queen</td>\n",
              "      <td>You and I</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Ooh-ooh\\n\\nMusic is playing in the darkness\\nA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>Queen</td>\n",
              "      <td>You Don’t Fool Me</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Oh\\n\\nYou don't fool me, you don't fool me\\nYo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5107</th>\n",
              "      <td>Queen</td>\n",
              "      <td>You Take My Breath Away</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Ooh\\nOoh, take it, take it all away\\nOoh\\nOoh,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5108</th>\n",
              "      <td>Queen</td>\n",
              "      <td>You’re My Best Friend</td>\n",
              "      <td>rock</td>\n",
              "      <td>en</td>\n",
              "      <td>Ooh, you make me live\\nWhatever this world can...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5109 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc592835-615f-41d7-a1ac-7c4fb5c99988')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc592835-615f-41d7-a1ac-7c4fb5c99988 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc592835-615f-41d7-a1ac-7c4fb5c99988');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the genre distribution. You can note that jazz and pop are the ones that have noticeably less songs present."
      ],
      "metadata": {
        "id": "hHvhNTNHsdwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs.groupby('Genre').size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3q1o6Vu02RD",
        "outputId": "76d10cc7-f98c-4c6f-a831-43a88e268638"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Genre\n",
              "jazz    1145\n",
              "pop     1102\n",
              "rap     1450\n",
              "rock    1412\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing text\n",
        "The first step is to lower everything, so that all the text would be uniform."
      ],
      "metadata": {
        "id": "J5l2__B6syBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs.Lyrics = songs.Lyrics.str.lower()\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHPFbJVpL_wN",
        "outputId": "9d36d4db-e16d-4a7d-9a07-a3ea037eefee"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    there ain't nothing i can do\\nor nothing i can...\n",
              "1    i need your love so badly\\ni love you, oh, so ...\n",
              "2    can't you see\\nwhat love and romance have done...\n",
              "3    like a little old fashioned music box\\nwith ju...\n",
              "4    a fine romance with no kisses\\na fine romance,...\n",
              "5    a sailboat in the moonlight and you\\nwouldn't ...\n",
              "6    a sunbonnet blue and a yellow straw hat\\nshy l...\n",
              "7    my yiddishe momme\\ni need her more then ever n...\n",
              "8    no one to talk with\\nall by myself\\nno one to ...\n",
              "9    there ain't nothing i can do\\nor nothing i can...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a regex pattern, remove all the punctuation, as well as any letters that are not in the English alphabet."
      ],
      "metadata": {
        "id": "X6J4DA38tFpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs.Lyrics = songs.Lyrics.str.replace(r\"[^A-za-z]\",\" \")\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Bk6hF89MhZB",
        "outputId": "c5c4bd29-9ccf-4820-d690-15221f3e5cda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    there ain t nothing i can do or nothing i can ...\n",
              "1    i need your love so badly i love you  oh  so m...\n",
              "2    can t you see what love and romance have done ...\n",
              "3    like a little old fashioned music box with jus...\n",
              "4    a fine romance with no kisses a fine romance  ...\n",
              "5    a sailboat in the moonlight and you wouldn t t...\n",
              "6    a sunbonnet blue and a yellow straw hat shy li...\n",
              "7    my yiddishe momme i need her more then ever no...\n",
              "8    no one to talk with all by myself no one to wa...\n",
              "9    there ain t nothing i can do or nothing i can ...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize every word. Tokenization is the process by which a large quantity of text is divided into smaller parts called tokens. Essentially, it splits the text into words, which would be helpful."
      ],
      "metadata": {
        "id": "g6lX0tfNtciU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs.Lyrics = list(map(word_tokenize, songs.Lyrics))\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-NtAv2aMzfM",
        "outputId": "f1d1241b-3160-489f-ded3-d6ff3ecb130b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [there, ain, t, nothing, i, can, do, or, nothi...\n",
              "1    [i, need, your, love, so, badly, i, love, you,...\n",
              "2    [can, t, you, see, what, love, and, romance, h...\n",
              "3    [like, a, little, old, fashioned, music, box, ...\n",
              "4    [a, fine, romance, with, no, kisses, a, fine, ...\n",
              "5    [a, sailboat, in, the, moonlight, and, you, wo...\n",
              "6    [a, sunbonnet, blue, and, a, yellow, straw, ha...\n",
              "7    [my, yiddishe, momme, i, need, her, more, then...\n",
              "8    [no, one, to, talk, with, all, by, myself, no,...\n",
              "9    [there, ain, t, nothing, i, can, do, or, nothi...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's remove all the stopwords from the text. They do not add much meaning to the sentence, so we won't be needing them."
      ],
      "metadata": {
        "id": "TeGuF4o2wHN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "def delete_stopword(words):\n",
        "    global stop_words\n",
        "    new_s = [word for word in words if word not in stop_words]\n",
        "    return new_s\n",
        "  \n",
        "songs.Lyrics = list(map(delete_stopword, songs.Lyrics))\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcqTe615NDNu",
        "outputId": "e5a33057-3126-400b-f826-8313b7a4cd44"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [nothing, nothing, say, want, anyway, care, pe...\n",
              "1    [need, love, badly, love, oh, madly, stand, gh...\n",
              "2    [see, love, romance, done, used, last, affair,...\n",
              "3    [like, little, old, fashioned, music, box, one...\n",
              "4    [fine, romance, kisses, fine, romance, friend,...\n",
              "5    [sailboat, moonlight, heaven, heaven, two, sof...\n",
              "6    [sunbonnet, blue, yellow, straw, hat, shy, lit...\n",
              "7    [yiddishe, momme, need, ever, yiddishe, momme,...\n",
              "8    [one, talk, one, walk, happy, shelf, misbehavi...\n",
              "9    [nothing, nothing, say, folks, criticize, goin...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, let's transform words into their normal, i.e. vocabulary form."
      ],
      "metadata": {
        "id": "3wqCN9ydwbx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatization(words):\n",
        "    global morph\n",
        "    new_s = [morph.parse(word)[0].normal_form for word in words]\n",
        "    return new_s\n",
        "\n",
        "songs.Lyrics = list(map(lemmatization, songs.Lyrics))\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nKD41WyNUfJ",
        "outputId": "846aa9e6-3a9e-4045-d2b9-f0df61889f56"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [nothing, nothing, say, want, anyway, care, pe...\n",
              "1    [need, love, badly, love, oh, madly, stand, gh...\n",
              "2    [see, love, romance, done, used, last, affair,...\n",
              "3    [like, little, old, fashioned, music, box, one...\n",
              "4    [fine, romance, kisses, fine, romance, friend,...\n",
              "5    [sailboat, moonlight, heaven, heaven, two, sof...\n",
              "6    [sunbonnet, blue, yellow, straw, hat, shy, lit...\n",
              "7    [yiddishe, momme, need, ever, yiddishe, momme,...\n",
              "8    [one, talk, one, walk, happy, shelf, misbehavi...\n",
              "9    [nothing, nothing, say, folks, criticize, goin...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting all the words that appear only once, since it is very likely they will not be adding semantic meaning and could be unqiue names or misspelled words."
      ],
      "metadata": {
        "id": "kVr5tDtzxKCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "def to_str(s):\n",
        "    new_s = ' '.join(j for j in s)\n",
        "    return new_s\n",
        "\n",
        "text_tokens = word_tokenize(' '.join(j for j in list(map(to_str, songs.Lyrics))))\n",
        "text = nltk.Text(text_tokens)\n",
        "fdist = FreqDist(text)\n",
        "words_to_del = list(filter(lambda k: fdist[k] == 1, fdist))\n",
        "\n",
        "def delete_word(words):\n",
        "    global words_to_del\n",
        "    new_s = [word for word in words if word not in words_to_del]\n",
        "    return new_s\n",
        "\n",
        "songs.Lyrics = list(map(delete_word, songs.Lyrics))\n",
        "songs.Lyrics = list(map(to_str, songs.Lyrics))\n",
        "songs.Lyrics[:10]"
      ],
      "metadata": {
        "id": "9HC1bpKONrGJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeaf8704-c7d8-4dfa-9de5-32237c7691d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    nothing nothing say want anyway care people ma...\n",
              "1    need love badly love oh madly stand ghost chan...\n",
              "2    see love romance done used last affair tragedy...\n",
              "3    like little old fashioned music box one tune p...\n",
              "4    fine romance kisses fine romance friend like c...\n",
              "5    sailboat moonlight heaven heaven two soft bree...\n",
              "6    sunbonnet blue yellow straw hat shy little dec...\n",
              "7    yiddishe momme need ever yiddishe momme long k...\n",
              "8    one talk one walk happy shelf misbehavin savin...\n",
              "9    nothing nothing say folks criticize going want...\n",
              "Name: Lyrics, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also encode the labels because we will be needing these for classification and the labels can be understood by the computer."
      ],
      "metadata": {
        "id": "hE5UErUFyuN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "songs.Genre = label_encoder.fit_transform(songs.Genre)\n",
        "  \n",
        "songs.Genre.unique()"
      ],
      "metadata": {
        "id": "W6yQGtduPrNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21842a85-d71c-4900-cf47-d3ced588d186"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the data into training and test, reserving 20% of the data for test:"
      ],
      "metadata": {
        "id": "p3K4yjFFy40d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(songs.Lyrics, songs.Genre, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WX4L2kPuGZWm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizing the data with two different methods:"
      ],
      "metadata": {
        "id": "I7eB581ty_2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "cv_train = cv.fit_transform(X_train)\n",
        "cv_test = cv.transform(X_test)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "ka2XbGYIQED8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "Atoy5AwyzEzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a logistic regression model, using the count vectorizer data and look at its accuracy."
      ],
      "metadata": {
        "id": "hodXImsEzHBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(cv_train, y_train)\n",
        "cv_pred = lr.predict(cv_test)\n",
        "print('cv test')\n",
        "print(classification_report(y_test, cv_pred))"
      ],
      "metadata": {
        "id": "rI5MqCyHQJys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980805d6-7f5e-484f-f2ac-ceb71149eec1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       246\n",
            "           1       0.62      0.60      0.61       220\n",
            "           2       0.83      0.82      0.83       272\n",
            "           3       0.70      0.73      0.72       284\n",
            "\n",
            "    accuracy                           0.76      1022\n",
            "   macro avg       0.75      0.75      0.75      1022\n",
            "weighted avg       0.75      0.76      0.76      1022\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do the same but with the TF-IDF data."
      ],
      "metadata": {
        "id": "VqUCS6hfzTVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(tfidf_train, y_train)\n",
        "tfidf_pred = lr.predict(tfidf_test)\n",
        "print('tf-idf test')\n",
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "metadata": {
        "id": "94-O6jZtQpPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ed8888-f9e5-43bb-fa57-1a88b07f4477"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83       246\n",
            "           1       0.70      0.61      0.65       220\n",
            "           2       0.88      0.85      0.86       272\n",
            "           3       0.70      0.79      0.74       284\n",
            "\n",
            "    accuracy                           0.78      1022\n",
            "   macro avg       0.78      0.77      0.77      1022\n",
            "weighted avg       0.78      0.78      0.78      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier\n",
        "Let's build a random forest classifier model, using the count vectorizer data and look at its accuracy."
      ],
      "metadata": {
        "id": "hyA468j1zab6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=3, n_jobs=-1, random_state=21)\n",
        "forest.fit(cv_train, y_train)\n",
        "cv_pred = forest.predict(cv_test)\n",
        "print('cv test')\n",
        "print(classification_report(y_test, cv_pred))"
      ],
      "metadata": {
        "id": "4ZpEcIOyQygn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc59d377-dc80-4c75-b85c-211455da215b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.71      0.60       246\n",
            "           1       0.42      0.35      0.38       220\n",
            "           2       0.83      0.63      0.72       272\n",
            "           3       0.50      0.52      0.51       284\n",
            "\n",
            "    accuracy                           0.56      1022\n",
            "   macro avg       0.57      0.55      0.55      1022\n",
            "weighted avg       0.57      0.56      0.56      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do the same but with the TF-IDF data."
      ],
      "metadata": {
        "id": "Q8eCLTk2znZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(tfidf_train, y_train)\n",
        "tfidf_pred = forest.predict(tfidf_test)\n",
        "print('tf-idf test')\n",
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "metadata": {
        "id": "EEn8o8S8Q1V-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd15cc8-13af-46b5-a3a6-0b88c0185483"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.70      0.58       246\n",
            "           1       0.45      0.37      0.40       220\n",
            "           2       0.82      0.65      0.73       272\n",
            "           3       0.51      0.50      0.50       284\n",
            "\n",
            "    accuracy                           0.56      1022\n",
            "   macro avg       0.57      0.55      0.55      1022\n",
            "weighted avg       0.58      0.56      0.56      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Model"
      ],
      "metadata": {
        "id": "KeKzfk8Lzzly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a SVC model, using the count vectorizer data and look at its accuracy."
      ],
      "metadata": {
        "id": "XEMX_xjpz0ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear', C=1.0)\n",
        "clf.fit(cv_train, y_train)\n",
        "cv_pred = clf.predict(cv_test)\n",
        "print('cv test')\n",
        "print(classification_report(y_test, cv_pred))"
      ],
      "metadata": {
        "id": "XRbDLegBRdEk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92236a9b-957f-46a3-d758-f2f42af056ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.83       246\n",
            "           1       0.57      0.58      0.58       220\n",
            "           2       0.82      0.79      0.80       272\n",
            "           3       0.68      0.67      0.67       284\n",
            "\n",
            "    accuracy                           0.72      1022\n",
            "   macro avg       0.72      0.72      0.72      1022\n",
            "weighted avg       0.72      0.72      0.72      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do the same but with the TF-IDF data."
      ],
      "metadata": {
        "id": "KPktuJlbz9JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='linear', C=1.0)\n",
        "clf.fit(tfidf_train, y_train)\n",
        "cv_pred = clf.predict(tfidf_test)\n",
        "print('tf-idf test')\n",
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "metadata": {
        "id": "igU9Xai7Rtuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa3ddca-9799-497b-9cd9-c43d6514372a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.70      0.58       246\n",
            "           1       0.45      0.37      0.40       220\n",
            "           2       0.82      0.65      0.73       272\n",
            "           3       0.51      0.50      0.50       284\n",
            "\n",
            "    accuracy                           0.56      1022\n",
            "   macro avg       0.57      0.55      0.55      1022\n",
            "weighted avg       0.58      0.56      0.56      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGB Model"
      ],
      "metadata": {
        "id": "Y07cND1j1aWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build an XGB model, using the count vectorizer data and look at its accuracy."
      ],
      "metadata": {
        "id": "pHmHRM8v1gkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "xgb = XGBClassifier(max_depth=10, n_estimators=50)\n",
        "xgb.fit(cv_train, y_train)\n",
        "cv_pred = lr.predict(cv_test)\n",
        "print('cv test')\n",
        "print(classification_report(y_test, cv_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoso8JQyt7fx",
        "outputId": "7b240957-e3c9-4620-c9bf-4834d9de52ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.44      0.59       246\n",
            "           1       0.53      0.63      0.57       220\n",
            "           2       0.56      0.94      0.70       272\n",
            "           3       0.68      0.43      0.53       284\n",
            "\n",
            "    accuracy                           0.61      1022\n",
            "   macro avg       0.67      0.61      0.60      1022\n",
            "weighted avg       0.67      0.61      0.60      1022\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's do the same but with the TF-IDF data."
      ],
      "metadata": {
        "id": "qVpZ4scx1oAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(max_depth=10, n_estimators=50)\n",
        "xgb.fit(tfidf_train, y_train)\n",
        "tfidf_pred = lr.predict(tfidf_test)\n",
        "print('tf-idf test')\n",
        "print(classification_report(y_test, tfidf_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO-asc2QuIMG",
        "outputId": "5a346941-f9ac-4926-d44e-03e707c79b7b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf-idf test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.84      0.83       246\n",
            "           1       0.70      0.61      0.65       220\n",
            "           2       0.88      0.85      0.86       272\n",
            "           3       0.70      0.79      0.74       284\n",
            "\n",
            "    accuracy                           0.78      1022\n",
            "   macro avg       0.78      0.77      0.77      1022\n",
            "weighted avg       0.78      0.78      0.78      1022\n",
            "\n"
          ]
        }
      ]
    }
  ]
}